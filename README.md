# laboratoriti
# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 10
## –ó–∞–¥–∞–Ω–∏–µ A
```python 
from collections import deque
from typing import Any, Deque, Iterable


class Stack:
    """
    –ü—Ä–æ—Å—Ç–æ–π —Å—Ç–µ–∫ (LIFO) –Ω–∞ –±–∞–∑–µ —Å–ø–∏—Å–∫–∞
    –í–µ—Ä—à–∏–Ω–∞ —Å—Ç–µ–∫–∞ ‚Äî –ø—Ä–∞–≤—ã–π –∫—Ä–∞–π —Å–ø–∏—Å–∫–∞
    """

    def __init__(self, items: Iterable[Any] | None = None) -> None:
        """–ú–æ–∂–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≥–æ—Ç–æ–≤–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é"""
        self._data: list[Any] = list(items) if items is not None else []

    def push(self, item: Any) -> None:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —ç–ª–µ–º–µ–Ω—Ç –Ω–∞ –≤–µ—Ä—à–∏–Ω—É —Å—Ç–µ–∫–∞"""
        self._data.append(item)

    def pop(self) -> Any:
        """
        –°–Ω–∏–º–∞–µ—Ç –≤–µ—Ä—Ö–Ω–∏–π —ç–ª–µ–º–µ–Ω—Ç —Å—Ç–µ–∫–∞
        –ü–æ–¥–Ω–∏–º–∞–µ—Ç IndexError, –µ—Å–ª–∏ —Å—Ç–µ–∫ –ø—É—Å—Ç
        """
        if self.is_empty():
            raise IndexError("–ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å pop: —Å—Ç–µ–∫ –ø—É—Å—Ç")
        return self._data.pop()

    def peek(self) -> Any | None:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–µ—Ä—Ö–Ω–∏–π —ç–ª–µ–º–µ–Ω—Ç –±–µ–∑ —É–¥–∞–ª–µ–Ω–∏—è
        –ï—Å–ª–∏ —Å—Ç–µ–∫ –ø—É—Å—Ç ‚Äî None
        """
        if self.is_empty():
            return None
        return self._data[-1]

    def is_empty(self) -> bool:
        """True, –µ—Å–ª–∏ —Å—Ç–µ–∫ –ø—É—Å—Ç"""
        return len(self._data) == 0

    def __len__(self) -> int:
        return len(self._data)

    def __repr__(self) -> str:
        return f"Stack({self._data!r})"


class Queue:
    """
    –û—á–µ—Ä–µ–¥—å FIFO –Ω–∞ –±–∞–∑–µ collections.deque
    –ì–æ–ª–æ–≤–∞ –æ—á–µ—Ä–µ–¥–∏ ‚Äî –ª–µ–≤—ã–π –∫—Ä–∞–π deque
    """

    def __init__(self, items: Iterable[Any] | None = None) -> None:
        """–ú–æ–∂–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≥–æ—Ç–æ–≤–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é"""
        self._data: Deque[Any] = deque(items or [])

    def enqueue(self, item: Any) -> None:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —ç–ª–µ–º–µ–Ω—Ç –≤ –∫–æ–Ω–µ—Ü –æ—á–µ—Ä–µ–¥–∏"""
        self._data.append(item)

    def dequeue(self) -> Any:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —ç–ª–µ–º–µ–Ω—Ç –∏–∑ –Ω–∞—á–∞–ª–∞ –æ—á–µ—Ä–µ–¥–∏
        –ü–æ–¥–Ω–∏–º–∞–µ—Ç IndexError, –µ—Å–ª–∏ –æ—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞
        """
        if self.is_empty():
            raise IndexError("–ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å dequeue: –æ—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞")
        return self._data.popleft()

    def peek(self) -> Any | None:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç –±–µ–∑ —É–¥–∞–ª–µ–Ω–∏—è
        –ï—Å–ª–∏ –æ—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞ ‚Äî None
        """
        if self.is_empty():
            return None
        return self._data[0]

    def is_empty(self) -> bool:
        """True, –µ—Å–ª–∏ –æ—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞"""
        return len(self._data) == 0

    def __len__(self) -> int:
        return len(self._data)

    def __repr__(self) -> str:
        return f"Queue({list(self._data)!r})"
```
## –ó–≤–¥–∞–Ω–∏–µ B
```python
from typing import Any, Iterator, Optional


class Node:
    """–£–∑–µ–ª –æ–¥–Ω–æ—Å–≤—è–∑–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞"""

    def __init__(self, value: Any, next: Optional["Node"] = None) -> None:
        self.value = value
        self.next = next

    def __repr__(self) -> str:
        return f"Node({self.value!r})"


class SinglyLinkedList:
    """
    –û–¥–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ø–∏—Å–æ–∫
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –∫–æ–Ω–µ—Ü –∏–ª–∏ –≤–Ω–∞—á–∞–ª–æ, –≤—Å—Ç–∞–≤–∫—É –ø–æ –∏–Ω–¥–µ–∫—Å—É –∏ —É–¥–∞–ª–µ–Ω–∏–µ –ø–æ –∏–Ω–¥–µ–∫—Å—É
    """

    def __init__(self) -> None:
        self.head: Optional[Node] = None
        self.tail: Optional[Node] = None
        self._size: int = 0

    def append(self, value: Any) -> None:
        """–î–æ–±–∞–≤–∏—Ç—å —ç–ª–µ–º–µ–Ω—Ç –≤ –∫–æ–Ω–µ—Ü —Å–ø–∏—Å–∫–∞ –∑–∞ O(1) —Å —É—á—ë—Ç–æ–º tail"""
        new_node = Node(value)
        if self.head is None:
            self.head = self.tail = new_node
        else:
            assert self.tail is not None  # –¥–ª—è —Ç–∏–ø–∞
            self.tail.next = new_node
            self.tail = new_node
        self._size += 1

    def prepend(self, value: Any) -> None:
        """–î–æ–±–∞–≤–∏—Ç—å —ç–ª–µ–º–µ–Ω—Ç –≤ –Ω–∞—á–∞–ª–æ —Å–ø–∏—Å–∫–∞ –∑–∞ O(1)"""
        new_node = Node(value, next=self.head)
        self.head = new_node
        if self.tail is None:
            self.tail = new_node
        self._size += 1

    def insert(self, idx: int, value: Any) -> None:
        """
        –í—Å—Ç–∞–≤–∏—Ç—å —ç–ª–µ–º–µ–Ω—Ç –ø–æ –∏–Ω–¥–µ–∫—Å—É
        –î–æ–ø—É—Å—Ç–∏–º—ã idx == 0 (–≤ –Ω–∞—á–∞–ª–æ) –∏ idx == len(list) (–≤ –∫–æ–Ω–µ—Ü)
        """
        if idx < 0 or idx > self._size:
            raise IndexError("–ò–Ω–¥–µ–∫—Å –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞")
        if idx == 0:
            self.prepend(value)
            return
        if idx == self._size:
            self.append(value)
            return

        prev = self._node_at(idx - 1)
        new_node = Node(value, next=prev.next)
        prev.next = new_node
        self._size += 1

    def remove_at(self, idx: int) -> None:
        """–£–¥–∞–ª–∏—Ç—å —ç–ª–µ–º–µ–Ω—Ç –ø–æ –∏–Ω–¥–µ–∫—Å—É. –ü–æ–¥–Ω–∏–º–∞–µ—Ç IndexError –ø—Ä–∏ –Ω–µ–≤–µ—Ä–Ω–æ–º –∏–Ω–¥–µ–∫—Å–µ"""
        if idx < 0 or idx >= self._size:
            raise IndexError("–ò–Ω–¥–µ–∫—Å –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞")

        if idx == 0:
            assert self.head is not None
            self.head = self.head.next
            if self.head is None:
                self.tail = None
            self._size -= 1
            return

        prev = self._node_at(idx - 1)
        assert prev.next is not None
        to_remove = prev.next
        prev.next = to_remove.next
        if prev.next is None:
            self.tail = prev
        self._size -= 1

    def _node_at(self, idx: int) -> Node:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —É–∑–µ–ª –ø–æ –∏–Ω–¥–µ–∫—Å—É (–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –ø–æ–º–æ—â–Ω–∏–∫, –±–µ–∑ –ø—Ä–æ–≤–µ—Ä–æ–∫ –≥—Ä–∞–Ω–∏—Ü)"""
        current = self.head
        for _ in range(idx):
            assert current is not None  # –¥–ª—è mypy/pyright
            current = current.next
        assert current is not None
        return current

    def __iter__(self) -> Iterator[Any]:
        current = self.head
        while current is not None:
            yield current.value
            current = current.next

    def __len__(self) -> int:
        return self._size

    def __repr__(self) -> str:
        values = ", ".join(repr(v) for v in self)
        return f"SinglyLinkedList([{values}])"
```
### deque
![deque](./images/lab10/deque.png)
### singly
![singly](./images/lab10/singly.png)
### stack 
![stack](./images/lab10/stack.png)
# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 9 
## –ó–∞–¥–∞–Ω–∏–µ A
```python
import csv
from pathlib import Path
from typing import List
import sys

try:
    from src.lab08.models import Student
except (ImportError, ValueError):
    project_root = Path(__file__).parent.parent.parent
    sys.path.insert(0, str(project_root))
    from src.lab08.models import Student


class Group:

    def __init__(self, storage_path: str):
        self.path = Path(storage_path)
        '''–°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∞–π–ª–∞, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç '''
        self._ensure_storage_exists()

    def _ensure_storage_exists(self):
        """–°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º, –µ—Å–ª–∏ –µ–≥–æ –µ—â—ë –Ω–µ—Ç"""
        if not self.path.exists():
            with open(self.path, "w", encoding="utf-8", newline="") as f:
                writer = csv.DictWriter(f, fieldnames=["fio", "birthdate", "group", "gpa"])
                writer.writeheader()

    def _read_all(self) -> List[dict]:
        """
        –ß–∏—Ç–∞–µ–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –∏–∑ CSV.
        """
        if not self.path.exists():
            return []
        
        rows = []
        with open(self.path, "r", encoding="utf-8", newline="") as f:
            reader = csv.DictReader(f)
            """–ï—Å–ª–∏ –Ω–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
            if reader.fieldnames != ["fio", "birthdate", "group", "gpa"]:
                raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç CSV: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –Ω–µ–≤–µ—Ä–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫")
            
            for row in reader:
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
                if any(row.values()):
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º gpa –≤ float
                    if "gpa" in row and row["gpa"]:
                        try:
                            row["gpa"] = float(row["gpa"])
                        except ValueError:
                            raise ValueError(f"–ù–µ–≤–µ—Ä–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ gpa: {row['gpa']}")
                    rows.append(row)
        
        return rows

    def _write_all(self, rows: List[dict]):
        with open(self.path, "w", encoding="utf-8", newline="") as f:
            writer = csv.DictWriter(f, fieldnames=["fio", "birthdate", "group", "gpa"])
            writer.writeheader()
            writer.writerows(rows)

    def list(self) -> List[Student]:
        rows = self._read_all()
        students = []
        for i, row in enumerate(rows):
            try:
                student = Student.from_dict(row)
                students.append(student)
            except (KeyError, ValueError) as e:
                raise ValueError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ Student –∏–∑ —Å—Ç—Ä–æ–∫–∏ {i + 2}: {e}")
        return students

    def add(self, student: Student):
        rows = self._read_all()
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º Student –≤ —Å–ª–æ–≤–∞—Ä—å –∏ –¥–æ–±–∞–≤–ª—è–µ–º
        student_dict = student.to_dict()
        rows.append(student_dict)
        self._write_all(rows)

    def find(self, substr: str) -> List[Student]:
        """
        –ù–∞–π—Ç–∏ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –ø–æ –ø–æ–¥—Å—Ç—Ä–æ–∫–µ –≤ fio
        """
        rows = self._read_all()
        matching_rows = [r for r in rows if substr.lower() in r["fio"].lower()]
        
        students = []
        for row in matching_rows:
            try:
                student = Student.from_dict(row)
                students.append(student)
            except (KeyError, ValueError) as e:
                raise ValueError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ Student: {e}")
        
        return students

    def remove(self, fio: str):
        """
        –£–¥–∞–ª–∏—Ç—å –∑–∞–ø–∏—Å—å(–∏) —Å –¥–∞–Ω–Ω—ã–º fio.
        """
        rows = self._read_all()
        # –£–¥–∞–ª—è–µ–º –≤—Å–µ –∑–∞–ø–∏—Å–∏ —Å —Å–æ–≤–ø–∞–¥–∞—é—â–∏–º fio
        rows = [r for r in rows if r["fio"] != fio]
        self._write_all(rows)

    def update(self, fio: str, **fields):
        """
        –û–±–Ω–æ–≤–∏—Ç—å –ø–æ–ª—è —Å—Ç—É–¥–µ–Ω—Ç–∞
        """
        rows = self._read_all()
        updated = False
        
        for row in rows:
            if row["fio"] == fio:
                for key, value in fields.items():
                    if key in ["fio", "birthdate", "group", "gpa"]:
                        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º gpa –≤ float, –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω–æ –∫–∞–∫ —Å—Ç—Ä–æ–∫–∞
                        if key == "gpa" and isinstance(value, str):
                            try:
                                value = float(value)
                            except ValueError:
                                raise ValueError(f"–ù–µ–≤–µ—Ä–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ gpa: {value}")
                        row[key] = value
                    else:
                        raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–µ –ø–æ–ª–µ: {key}")
                try:
                    Student.from_dict(row)
                except (KeyError, ValueError) as e:
                    raise ValueError(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
                
                updated = True
                break
        
        if not updated:
            raise ValueError(f"–°—Ç—É–¥–µ–Ω—Ç —Å –§–ò–û '{fio}' –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        self._write_all(rows)


# if __name__ == '__main__':
    
#     #–°–æ–∑–¥–∞—ë–º –≥—Ä—É–ø–ø—É
#     group = Group('data/lab09/students.csv')
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—á–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    # students = group.list()
    # for s in students:
    #     print(f"- {s}")
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—É–¥–µ–Ω—Ç–æ–≤
    # students_to_add = [
    #     Student("–ò–≤–∞–Ω–æ–≤ –ü–∏—Ç–µ—Ä", "2003-10-10", "–ë–ò–í–¢-21-1", 4.3),
    #     Student("–ü–µ—Ç—Ä–æ–≤ –ü–µ—Ç—Ä", "2002-05-20", "SE-01", 4.5),
    #     Student("–í–º–Ω–æ–∫—É—Ä–æ–≤–∞ –ê–Ω–∞—Å—Ç–∞—Å–∏—è", "2004-03-15", "–ë–ò–í–¢-21-1", 4.8),
    # ]
    
    # for student in students_to_add:
    #     group.add(student)
    
    # #–ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Å—Ç—É–¥–µ–Ω—Ç–æ–≤
    # all_students = group.list()
    # for i, student in enumerate(all_students, 1):
    #     print(f"{i}. {student}")
    
    # –ü–æ–∏—Å–∫ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤
    # found = group.find("–ò–≤–∞–Ω–æ–≤")
    # for student in found:
    #     print(f"–ù–∞–π–¥–µ–Ω: {student}")
    
    # #–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    # group.update("–ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω", gpa=4.9)
    # # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—á–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –ø–æ–ª–Ω–æ–º—É –§–ò–û, –∞ –Ω–µ –ø–æ –ø–æ–¥—Å—Ç—Ä–æ–∫–µ
    # updated_student = group.find("–ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω")[0]
    # print(f"–û–±–Ω–æ–≤–ª—ë–Ω: {updated_student}")
    
    # #–§–∏–Ω–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫
    # final_students = group.list()
    # for i, student in enumerate(final_students, 1):
    #     print(f"{i}. {student}")
    
    # #–£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—É–¥–µ–Ω—Ç–∞
    # group.remove("–ü–µ—Ç—Ä–æ–≤ –ü–µ—Ç—Ä")

    
    # #–°–ø–∏—Å–æ–∫ –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è
    # remaining = group.list()
    # for i, student in enumerate(remaining, 1):
    #     print(f"{i}. {student}")
```
### –ò—Å—Ö–æ–¥–Ω–∏–∫ csv
![11](./images/lab09/isxodnii.png)
### –ò—Å—Ö–æ–¥–Ω–∏–∫ —Ç–µ—Ä–º–∏–Ω–∞–ª 
![12](./images/lab09/isxodniii.png)
### add
![13](./images/lab09/add.png)
### find
![14](./images/lab09/find.png)
### delete
![15](./images/lab09/delete.png)
### update 
![16](./images/lab09/update.png)
# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–∞–Ω—è —Ä–∞–±–æ—Ç–∞ 8
## –ó–∞–¥–∞–Ω–∏–µ A
```python
from dataclasses import dataclass
from datetime import datetime, date


@dataclass
class Student:
    fio: str
    birthdate: str
    group: str
    gpa: float

    def __post_init__(self):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–∞ –¥–∞—Ç—ã –∏ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ gpa"""
        try:
            datetime.strptime(self.birthdate, "%Y-%m-%d")
        except ValueError:
            raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã")
        
        if not (0 <= self.gpa <= 5):
            raise ValueError("gpa –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç 0 –¥–æ 5")

    def age(self) -> int:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª–Ω—ã—Ö –ª–µ—Ç —Å—Ç—É–¥–µ–Ω—Ç–∞"""
        birth_date = datetime.strptime(self.birthdate, "%Y-%m-%d").date()
        today = date.today()
        age = today.year - birth_date.year
        
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—Ä –≤ —ç—Ç–æ–º –≥–æ–¥—É"""
        if today.month < birth_date.month or (today.month == birth_date.month and today.day < birth_date.day):
            age -= 1
        
        return age

    def to_dict(self) -> dict:
        """–°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—ä–µ–∫—Ç–∞ Student –≤ —Å–ª–æ–≤–∞—Ä—å"""

        name_parts = self.fio.strip().split()
        name_surname = " ".join(name_parts[:2]) if len(name_parts) >= 2 else self.fio
        
        return {
            "fio": name_surname,
            "birthdate": self.birthdate,
            "group": self.group,
            "gpa": self.gpa
        }

    @classmethod
    def from_dict(cls, d: dict):
        """–î–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–ª–æ–≤–∞—Ä—è –≤ –æ–±—ä–µ–∫—Ç Student"""
        return cls(
            fio=d["fio"],
            birthdate=d["birthdate"],
            group=d["group"],
            gpa=d["gpa"]
        )

    def __str__(self):
        """–ö—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å—Ç—É–¥–µ–Ω—Ç–µ"""
        return f"–°—Ç—É–¥–µ–Ω—Ç: {self.fio}, –ì—Ä—É–ø–ø–∞: {self.group}, GPA: {self.gpa}, –í–æ–∑—Ä–∞—Å—Ç: {self.age()} –ª–µ—Ç"


if __name__ == "__main__":
    student = Student(
        fio="–í–∏–Ω–æ–≥—Ä–∞–¥–æ–≤ –ê–Ω—Ç–æ–Ω –ó—É–º–µ—Ä–æ–≤–∏—á",
        birthdate="2006-05-15",
        group="BBIT-06-1",
        gpa=4.5
    )
    print(student)
    print(f"–°–ª–æ–≤–∞—Ä—å: {student.to_dict()}")
```
![A](./images/lab08/A.png)

## –ó–∞–¥–∞–Ω–∏–µ B
```python
import json
import sys
from pathlib import Path
from typing import List

try:
    from .models import Student
except (ImportError, ValueError):
    
    project_root = Path(__file__).parent.parent.parent
    sys.path.insert(0, str(project_root))
    from src.lab08.models import Student


def students_to_json(students: List[Student], path: str) -> None:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –≤ JSON —Ñ–∞–π–ª.
    """
    data = [s.to_dict() for s in students]
    
    try:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except IOError as e:
        raise IOError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ —Ñ–∞–π–ª–∞: {e}")


def students_from_json(path: str) -> List[Student]:
    """
    –ß–∏—Ç–∞–µ—Ç JSON-–º–∞—Å—Å–∏–≤, –≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏ —Å–æ–∑–¥–∞—ë—Ç —Å–ø–∏—Å–æ–∫ Student.
    """
    try:
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
    except FileNotFoundError:
        raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")
    except json.JSONDecodeError as e:
        raise ValueError(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç JSON: {e}")
    
    if not isinstance(data, list):
        raise ValueError("JSON –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤")
    
    students = []
    for i, item in enumerate(data):
        if not isinstance(item, dict):
            raise ValueError(f"–≠–ª–µ–º–µ–Ω—Ç {i} –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä—ë–º")
            
        try:
            student = Student.from_dict(item)
            students.append(student)
        except (KeyError, ValueError) as e:
            raise ValueError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ Student –∏–∑ —ç–ª–µ–º–µ–Ω—Ç–∞ {i}: {e}")
    
    return students


if __name__ == "__main__":

    from pathlib import Path
    
    project_root = Path(__file__).parent.parent.parent
    input_path = project_root / "data" / "lab08" / "students_input.json"
    output_path = project_root / "data" / "lab08" / "students_output.json"
    
    students = students_from_json(str(input_path))
    
    for student in students:
        print(f"‚Ä¢ {student}")
    
    students_to_json(students, str(output_path))
```
### –ò—Å—Ö–æ–¥–Ω—ã–π json
![isx](./images/lab08/B1.png)
### –í—ã—Ö–æ–¥–Ω–æ–π json
![vix](./images/lab08/B2.png)
# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–∞–Ω—è —Ä–∞–±–æ—Ç–∞ 7 
## –ó–∞–¥–∞–Ω–∏–µ A
```python 
import pytest
from src.lib.text import normalize, tokenize, count_freq, top_n


"""–ë–∞–∑–æ–≤—ã–µ —Å–ª—É—á–∞–∏"""
@pytest.mark.parametrize(
    "source, expected",
    [
        ("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t", "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"),
        ("—ë–∂–∏–∫, –Å–ª–∫–∞", "–µ–∂–∏–∫, –µ–ª–∫–∞"),
        ("Hello\r\nWorld", "hello world"),
        ("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ", "–¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã"),
    ],
)
def test_normalize_basic(source, expected):
    assert normalize(source) == expected


"""–ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞"""
def test_normalize_empty_string():
    assert normalize("") == ""


"""–¢–æ–ª—å–∫–æ –ø—Ä–æ–±–µ–ª—ã"""
def test_normalize_whitespace_only():
    assert normalize("   \t\n\r   ") == ""


"""–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —á–∏—Å–µ–ª"""
@pytest.mark.parametrize(
    "text, expected",
    [
        ("test123", "test123"),
        ("123test", "123test"),
        ("abc def", "abc def"),
    ],
)
def test_normalize_with_numbers(text, expected):
    assert normalize(text) == expected


"""–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–æ–≤ –∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏"""
def test_normalize_special_characters():
    assert normalize("hello, world!") == "hello, world!"
    assert normalize("test@email.com") == "test@email.com"


"""yo2e=False"""
def test_normalize_with_yo2e_false():
    assert normalize("—ë–∂–∏–∫", yo2e=False) == "—ë–∂–∏–∫"


"""casefold=False"""
def test_normalize_with_casefold_false():
    assert normalize("–ü—Ä–ò–≤–ï—Ç", casefold=False) == "–ü—Ä–ò–≤–ï—Ç"
    assert normalize("Hello", casefold=False) == "Hello"


"""–ë–∞–∑–æ–≤—ã–µ —Å–ª—É—á–∞–∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏"""
@pytest.mark.parametrize(
    "text, expected",
    [
        ("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä", ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä"]),
        ("hello,world!!!", ["hello", "world"]),
        ("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ", ["–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É", "–∫—Ä—É—Ç–æ"]),
        ("2025 –≥–æ–¥", ["2025", "–≥–æ–¥"]),
    ],
)
def test_tokenize_basic(text, expected):
    assert tokenize(text) == expected


"""–ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞"""
def test_tokenize_empty_string():
    assert tokenize("") == []


"""–¢–æ–ª—å–∫–æ –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è"""
def test_tokenize_only_punctuation():
    assert tokenize("!@#$%^&*()") == []


"""–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —Å –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è–º–∏"""
def test_tokenize_with_underscores():
    assert tokenize("hello_world test_case") == ["hello_world", "test_case"]


"""–ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –º–µ–∂–¥—É —Å–ª–æ–≤–∞–º–∏"""
def test_tokenize_multiple_spaces():
    assert tokenize("hello     world") == ["hello", "world"]


"""–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —Å–ª–æ–≤ —Å –¥–µ—Ñ–∏—Å–∞–º–∏"""
def test_tokenize_with_hyphens():
    assert tokenize("self-driving-car") == ["self-driving-car"]
    assert tokenize("-start middle- end-") == ["start", "middle-", "end-"]


"""–°–º–µ—à–∞–Ω–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã"""
def test_tokenize_mixed_content():
    assert tokenize("test123 hello456world") == ["test123", "hello456world"]


"""–ü–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫ –∏ —Ç–∞–±—É–ª—è—Ü–∏—è"""
def test_tokenize_newlines_and_tabs():
    assert tokenize("hello\nworld\ttest") == ["hello", "world", "test"]


"""–ë–∞–∑–æ–≤—ã–π —Å–ª—É—á–∞–π –ø–æ–¥—Å—á–µ—Ç–∞ —á–∞—Å—Ç–æ—Ç"""
def test_count_freq_basic():
    tokens = ["a", "b", "a", "c", "b", "a"]
    expected = {"a": 3, "b": 2, "c": 1}
    assert count_freq(tokens) == expected


"""–ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫"""
def test_count_freq_empty_list():
    """–ì—Ä–∞–Ω–∏—á–Ω—ã–π —Å–ª—É—á–∞–π: –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫"""
    assert count_freq([]) == {}


"""–û–¥–∏–Ω —Ç–æ–∫–µ–Ω"""
def test_count_freq_single_token():
    assert count_freq(["hello"]) == {"hello": 1}


"""–í—Å–µ —Ç–æ–∫–µ–Ω—ã –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ"""
def test_count_freq_all_same():
    tokens = ["test", "test", "test", "test"]
    assert count_freq(tokens) == {"test": 4}


"""–í—Å–µ —Ç–æ–∫–µ–Ω—ã —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ"""
def test_count_freq_all_unique():
    tokens = ["a", "b", "c", "d", "e"]
    expected = {"a": 1, "b": 1, "c": 1, "d": 1, "e": 1}
    assert count_freq(tokens) == expected


"""–ü–æ–¥—Å—á–µ—Ç —á–∞—Å—Ç–æ—Ç —Å —á–∏—Å–ª–∞–º–∏"""
def test_count_freq_with_numbers():
    tokens = ["123", "abc", "123", "abc", "123"]
    expected = {"123": 3, "abc": 2}
    assert count_freq(tokens) == expected


"""–ë–∞–∑–æ–≤—ã–π —Å–ª—É—á–∞–π: —Ç–æ–ø-N –ø–æ —á–∞—Å—Ç–æ—Ç–µ"""
def test_top_n_basic():
    freq = {"apple": 5, "banana": 3, "cherry": 8, "date": 2}
    result = top_n(freq, n=2)
    assert result == [("cherry", 8), ("apple", 5), ("banana", 3), ("date", 2)]


"""–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É –ø—Ä–∏ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π —á–∞—Å—Ç–æ—Ç–µ"""
def test_top_n_tie_breaker():
    freq = {"bb": 2, "aa": 2, "cc": 3}
    result = top_n(freq, n=10)
    assert result == [("cc", 3), ("aa", 2), ("bb", 2)]


"""–ü—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å"""
def test_top_n_empty_dict():
    assert top_n({}, n=5) == []


"""–û–¥–∏–Ω —ç–ª–µ–º–µ–Ω—Ç –≤ —Å–ª–æ–≤–∞—Ä–µ"""
def test_top_n_single_item():
    assert top_n({"test": 10}, n=5) == [("test", 10)]


"""–í—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Å –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π —á–∞—Å—Ç–æ—Ç–æ–π"""
def test_top_n_all_same_frequency():
    freq = {"dog": 1, "cat": 1, "bird": 1, "ant": 1}
    result = top_n(freq, n=10)
    assert result == [("ant", 1), ("bird", 1), ("cat", 1), ("dog", 1)]


"""–ö–æ–≥–¥–∞ n –±–æ–ª—å—à–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —ç–ª–µ–º–µ–Ω—Ç–æ–≤"""
def test_top_n_returns_all_when_n_larger():
    freq = {"a": 1, "b": 2}
    result = top_n(freq, n=100)
    assert len(result) == 2
    assert result == [("b", 2), ("a", 1)]


"""–°–º–µ—Å—å —á–∞—Å—Ç–æ—Ç –∏ –∞–ª—Ñ–∞–≤–∏—Ç–∞"""
def test_top_n_complex_sorting():
    freq = {"z": 5, "a": 5, "m": 5, "b": 3, "y": 3, "c": 1}
    result = top_n(freq, n=10)
    assert result == [("a", 5), ("m", 5), ("z", 5), ("b", 3), ("y", 3), ("c", 1)]
```


## –ó–∞–¥–∞–Ω–∏–µ B
```python 
import pytest
import json
import csv
from pathlib import Path
from src.lab05.json_csv import json_to_csv, csv_to_json

"""–ë–∞–∑–æ–≤–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è JSON -> CSV"""
def test_json_to_csv_basic(tmp_path: Path):
    src = tmp_path / "people.json"
    dst = tmp_path / "people.csv"

    data = [
        {"name": "Alice", "age": "22"},
        {"name": "Bob", "age": "25"},
    ]
    src.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")

    json_to_csv(str(src), str(dst))

    with dst.open(encoding="utf-8") as f:
        rows = list(csv.DictReader(f))

    assert len(rows) == 2
    assert {"name", "age"} <= set(rows[0].keys())
    assert rows[0]["name"] == "Alice"
    assert rows[0]["age"] == "22"
    assert rows[1]["name"] == "Bob"
    assert rows[1]["age"] == "25"


"""–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –ø–æ–ª—è–º–∏"""
def test_json_to_csv_multiple_fields(tmp_path: Path):
    src = tmp_path / "data.json"
    dst = tmp_path / "data.csv"

    data = [
        {"id": "1", "name": "John", "city": "Moscow", "salary": "50000"},
        {"id": "2", "name": "Jane", "city": "Paris", "salary": "60000"},
        {"id": "3", "name": "Jack", "city": "London", "salary": "55000"},
    ]
    src.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")

    json_to_csv(str(src), str(dst))

    with dst.open(encoding="utf-8") as f:
        rows = list(csv.DictReader(f))

    assert len(rows) == 3
    assert {"id", "name", "city", "salary"} <= set(rows[0].keys())


"""–¢–µ—Å—Ç —Ñ–æ—Ä–º–∞—Ç–∞ (UTF-8)"""
def test_json_to_csv_cyrillic(tmp_path: Path):
    src = tmp_path / "russian.json"
    dst = tmp_path / "russian.csv"

    data = [
        {"–∏–º—è": "–ê–ª–µ–∫—Å–µ–π", "–≤–æ–∑—Ä–∞—Å—Ç": "30"},
        {"–∏–º—è": "–ú–∞—Ä–∏—è", "–≤–æ–∑—Ä–∞—Å—Ç": "28"},
    ]
    src.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")

    json_to_csv(str(src), str(dst))

    with dst.open(encoding="utf-8") as f:
        rows = list(csv.DictReader(f))

    assert len(rows) == 2
    assert rows[0]["–∏–º—è"] == "–ê–ª–µ–∫—Å–µ–π"
    assert rows[1]["–∏–º—è"] == "–ú–∞—Ä–∏—è"


"""–§–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"""
def test_json_to_csv_file_not_found(tmp_path: Path):
    src = tmp_path / "nonexistent.json"
    dst = tmp_path / "output.csv"

    with pytest.raises(FileNotFoundError):
        json_to_csv(str(src), str(dst))


"""–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON"""
def test_json_to_csv_invalid_json(tmp_path: Path):
    src = tmp_path / "invalid.json"
    dst = tmp_path / "output.csv"

    src.write_text("{ this is not valid json }", encoding="utf-8")

    with pytest.raises(ValueError):
        json_to_csv(str(src), str(dst))


"""–ü—É—Å—Ç–æ–π JSON"""
def test_json_to_csv_empty_file(tmp_path: Path):
    src = tmp_path / "empty.json"
    dst = tmp_path / "output.csv"

    src.write_text("[]", encoding="utf-8")

    with pytest.raises(ValueError, match="–ø—É—Å—Ç"):
        json_to_csv(str(src), str(dst))


"""JSON –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ø–∏—Å–∫–æ–º"""
def test_json_to_csv_not_list(tmp_path: Path):
    src = tmp_path / "notlist.json"
    dst = tmp_path / "output.csv"

    data = {"name": "Alice", "age": 22}
    src.write_text(json.dumps(data), encoding="utf-8")

    with pytest.raises(ValueError, match="—Å–ø–∏—Å–æ–∫"):
        json_to_csv(str(src), str(dst))


"""–≠–ª–µ–º–µ–Ω—Ç—ã —Å–ø–∏—Å–∫–∞ –Ω–µ —Å–ª–æ–≤–∞—Ä–∏"""
def test_json_to_csv_not_dict_elements(tmp_path: Path):
    src = tmp_path / "notdict.json"
    dst = tmp_path / "output.csv"

    data = ["string1", "string2", "string3"]
    src.write_text(json.dumps(data), encoding="utf-8")

    with pytest.raises(ValueError, match="—Å–ª–æ–≤–∞—Ä—è–º–∏"):
        json_to_csv(str(src), str(dst))


"""–ù–µ–≤–µ—Ä–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞"""
def test_json_to_csv_wrong_extension(tmp_path: Path):

    src = tmp_path / "file.txt"
    dst = tmp_path / "output.csv"

    with pytest.raises(TypeError, match="—Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ"):
        json_to_csv(str(src), str(dst))


"""–ù–µ–≤–µ—Ä–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –¥–ª—è CSV"""
def test_json_to_csv_wrong_csv_extension(tmp_path: Path):
    src = tmp_path / "file.json"
    dst = tmp_path / "output.txt"

    src.write_text('[{"name": "test"}]', encoding="utf-8")

    with pytest.raises(TypeError, match="—Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ"):
        json_to_csv(str(src), str(dst))


"""–ë–∞–∑–æ–≤–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è CSV -> JSON"""
def test_csv_to_json_basic(tmp_path: Path):

    src = tmp_path / "people.csv"
    dst = tmp_path / "people.json"

    with src.open("w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=["name", "age"])
        writer.writeheader()
        writer.writerow({"name": "Alice", "age": "22"})
        writer.writerow({"name": "Bob", "age": "25"})

    csv_to_json(str(src), str(dst))

    with dst.open(encoding="utf-8") as f:
        data = json.load(f)

    assert len(data) == 2
    assert data[0]["name"] == "Alice"
    assert data[0]["age"] == "22"
    assert data[1]["name"] == "Bob"
    assert data[1]["age"] == "25"


"""–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è CSV —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –ø–æ–ª—è–º–∏"""
def test_csv_to_json_multiple_fields(tmp_path: Path):
    src = tmp_path / "data.csv"
    dst = tmp_path / "data.json"

    with src.open("w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=["id", "name", "city", "salary"])
        writer.writeheader()
        writer.writerow(
            {"id": "1", "name": "John", "city": "Moscow", "salary": "50000"}
        )
        writer.writerow({"id": "2", "name": "Jane", "city": "Paris", "salary": "60000"})

    csv_to_json(str(src), str(dst))

    with dst.open(encoding="utf-8") as f:
        data = json.load(f)

    assert len(data) == 2
    assert set(data[0].keys()) == {"id", "name", "city", "salary"}


"""–¢–µ—Å—Ç UTF-8"""
def test_csv_to_json_cyrillic(tmp_path: Path):
    src = tmp_path / "russian.csv"
    dst = tmp_path / "russian.json"

    with src.open("w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=["–∏–º—è", "–≤–æ–∑—Ä–∞—Å—Ç"])
        writer.writeheader()
        writer.writerow({"–∏–º—è": "–ê–ª–µ–∫—Å–µ–π", "–≤–æ–∑—Ä–∞—Å—Ç": "30"})
        writer.writerow({"–∏–º—è": "–ú–∞—Ä–∏—è", "–≤–æ–∑—Ä–∞—Å—Ç": "28"})

    csv_to_json(str(src), str(dst))

    with dst.open(encoding="utf-8") as f:
        data = json.load(f)

    assert len(data) == 2
    assert data[0]["–∏–º—è"] == "–ê–ª–µ–∫—Å–µ–π"
    assert data[1]["–∏–º—è"] == "–ú–∞—Ä–∏—è"


"""–§–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"""
def test_csv_to_json_file_not_found(tmp_path: Path):
    src = tmp_path / "nonexistent.csv"
    dst = tmp_path / "output.json"

    with pytest.raises(FileNotFoundError):
        csv_to_json(str(src), str(dst))


"""–ü—É—Å—Ç–æ–π CSV —Ñ–∞–π–ª"""
def test_csv_to_json_empty_file(tmp_path: Path):
    src = tmp_path / "empty.csv"
    dst = tmp_path / "output.json"

    src.write_text("", encoding="utf-8")

    with pytest.raises(ValueError, match="–ø—É—Å—Ç"):
        csv_to_json(str(src), str(dst))


"""–¢–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö"""
def test_csv_to_json_only_header(tmp_path: Path):
    src = tmp_path / "header_only.csv"
    dst = tmp_path / "output.json"

    with src.open("w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=["name", "age"])
        writer.writeheader()

    with pytest.raises(ValueError, match="–ø—É—Å—Ç"):
        csv_to_json(str(src), str(dst))


"""–ù–µ–≤–µ—Ä–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞"""
def test_csv_to_json_wrong_extension(tmp_path: Path):

    src = tmp_path / "file.txt"
    dst = tmp_path / "output.json"

    with pytest.raises(TypeError, match="—Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ"):
        csv_to_json(str(src), str(dst))


"""–ù–µ–≤–µ—Ä–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –¥–ª—è JSON"""
def test_csv_to_json_wrong_json_extension(tmp_path: Path):
    src = tmp_path / "file.csv"
    dst = tmp_path / "output.txt"

    src.write_text("name,age\ntest,25", encoding="utf-8")

    with pytest.raises(TypeError, match="—Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ"):
        csv_to_json(str(src), str(dst))
```
![pic2](./images/lab07/test.png)
## –ó–∞–¥–∞–Ω–∏–µ C 
![pic](./images/lab07/black-.png)
![pic1](./images/lab07/black+.png)
# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 6
## –ó–∞–¥–∞–Ω–∏–µ 1
```python
import argparse
import os
import sys
from pathlib import Path

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from lab04.text_report import frequencies_from_text, sorted_word

def main():
    parser = argparse.ArgumentParser(description="CLI‚Äë—É—Ç–∏–ª–∏—Ç—ã –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ–π ‚Ññ6")
    subparsers = parser.add_subparsers(dest="command")

    cat_pars = subparsers.add_parser("cat", help="–í—ã–≤–µ—Å—Ç–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞")
    cat_pars.add_argument("--input", required=True, help='–ü—É—Ç—å –∫ —Ñ—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É')
    cat_pars.add_argument("-n", action="store_true", help="–ù—É–º–µ—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫–∏")
    
    stats_pars = subparsers.add_parser("stats", help="–ß–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤")  
    stats_pars.add_argument("--input", required=True)
    stats_pars.add_argument("--top", type=int, default=5)

    args = parser.parse_args()

    if args.command == "cat":
        input_path = Path(args.input)
        if not input_path.exists():
            cat_pars.error(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: '{args.input}'")
        
        try:
            for i, line in enumerate(input_path.read_text(encoding='utf-8').splitlines()):
                print(f"{i + 1}. {line}" if args.n else line)
        except Exception as e:
            cat_pars.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
            
    elif args.command == "stats":
        if args.top <= 0:
            stats_pars.error(f"--top –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º —á–∏—Å–ª–æ–º, –ø–æ–ª—É—á–µ–Ω–æ: {args.top}")
        
        input_path = Path(args.input)
        if not input_path.exists():
            stats_pars.error(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: '{args.input}'")
        
        try:
            new_str = input_path.read_text(encoding='utf-8')
            sorted_list = sorted_word(frequencies_from_text(new_str))
            for word, count in sorted_list[:args.top]:
                print(f"{word}: {count}")
        
        except Exception as e:
            stats_pars.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {e}")

if __name__ == "__main__":
    main()
```
##cat - –≤—ã–≤–æ–¥ —Å—Ç—Ä–æ–∫ —Å –Ω–æ–º–µ—Ä–∞–º–∏ 
![cat](./images/lab06/cat.png)
##stats - –≤—ã–≤–æ–¥ —Ç–æ–ø —Å–ª–æ–≤ —Ñ–∞–π–ª–∞
![cat](./images/lab06/stats.png)
## –ó–∞–¥–∞–Ω–∏–µ 2 
```python 
import argparse
import os
import sys

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from lab05.json_csv import json_to_csv, csv_to_json
from lab05.csv_xlsx import csv_to_xlsx

def main():
    parser = argparse.ArgumentParser(description="–ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö")
    sub = parser.add_subparsers(dest="command")

    parser1 = sub.add_parser("json2csv")
    parser1.add_argument("--in", dest="input", required=True)
    parser1.add_argument("--out", dest="output", required=True)

    parser2 = sub.add_parser("csv2json")
    parser2.add_argument("--in", dest="input", required=True)
    parser2.add_argument("--out", dest="output", required=True)

    p3 = sub.add_parser("csv2xlsx")
    p3.add_argument("--in", dest="input", required=True)
    p3.add_argument("--out", dest="output", required=True)

    args = parser.parse_args()
    if args.command == "json2csv":
        json_to_csv(args.input, args.output)    
    elif args.command == "csv2json":
        csv_to_json(args.input, args.output)
    elif args.command == "csv2xlsx":
        csv_to_xlsx(args.input, args.output)

if __name__ == "__main__":
    main()
```
##file operation
![sec](./images/lab06/sec.png)

# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 5
## –ó–∞–¥–∞–Ω–∏–µ A
```python 
import json
import csv

def json_to_csv(json_path: str, csv_path: str) -> None:
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç JSON-—Ñ–∞–π–ª –≤ CSV.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π [{...}, {...}], –∑–∞–ø–æ–ª–Ω—è–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è –ø—É—Å—Ç—ã–º–∏ —Å—Ç—Ä–æ–∫–∞–º–∏.
    –ö–æ–¥–∏—Ä–æ–≤–∫–∞ UTF-8. –ü–æ—Ä—è–¥–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ ‚Äî –∫–∞–∫ –≤ –ø–µ—Ä–≤–æ–º –æ–±—ä–µ–∫—Ç–µ –∏–ª–∏ –∞–ª—Ñ–∞–≤–∏—Ç–Ω—ã–π (—É–∫–∞–∑–∞—Ç—å –≤ README).
    """
    if not json_path.endswith('.json'): 
        raise TypeError("–ù–µ–≤–µ—Ä–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ(only .json)")
    if not csv_path.endswith('.csv'):
        raise TypeError("–ù–µ–≤–µ—Ä–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ(olnly .csv)")

    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            dannie = json.load(f)
    except FileNotFoundError:
        raise FileNotFoundError("–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
    except json.JSONDecodeError as e:
        raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è")
    

    if not isinstance(dannie, list):
        raise ValueError("JSON –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤")
    if len(dannie) == 0:
        raise ValueError("JSON-—Ñ–∞–π–ª –ø—É—Å—Ç")
    if not isinstance(dannie[0], dict):
        raise ValueError("–≠–ª–µ–º–µ–Ω—Ç—ã —Å–ø–∏—Å–∫–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä—è–º–∏")
    
    zagolovki = list(dannie[0].keys())
    
    try:
        with open(csv_path, 'w', newline='', encoding='utf-8') as csv_file:
            isxod = csv.DictWriter(csv_file, fieldnames=zagolovki)
            isxod.writeheader()
            isxod.writerows(dannie)
    except IOError as e:
        raise IOError(f"–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ {e}")

json_to_csv('data/lab05/samples/people.json', 'data/lab05/out/people_from_json.csv')


def csv_to_json(csv_path: str, json_path: str) -> None:
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç CSV –≤ JSON (—Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π).
    –ó–∞–≥–æ–ª–æ–≤–æ–∫ –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω, –∑–Ω–∞—á–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –∫–∞–∫ —Å—Ç—Ä–æ–∫–∏.
    json.dump(..., ensure_ascii=False, indent=2)
    """
    
    if not csv_path.endswith('.csv'):
        raise TypeError("–ù–µ–≤–µ—Ä–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ(only .csv)")
    if not json_path.endswith('.json'):
        raise TypeError("–ù–µ–≤–µ—Ä–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ(only .json)")
    
    rows = []
    try:
        with open(csv_path, 'r', encoding='utf-8') as csv_file:
            reader = csv.DictReader(csv_file)#—á–∏—Ç–∞–µ–º —Å–ª–æ–≤–∞—Ä–∏
            rows = list(reader)
    except FileNotFoundError:
        raise FileNotFoundError("–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
  
    if not rows:
        raise ValueError("CSV —Ñ–∞–π–ª –ø—É—Å—Ç")
    
    try:
        with open(json_path, 'w', encoding='utf-8') as json_file:
            json.dump(rows, json_file, ensure_ascii=False, indent=2)
    except IOError as e:
        raise IOError(f"–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ {e}")


csv_to_json('data/lab05/samples/testik.csv', 'data/lab05/out/testik.json')
```
### –ò—Å—Ö–æ–¥–Ω–∏–∫ .json
![testik_json](./images/lab05/testik_json.png)
### –†–µ–∑—É–ª—å—Ç–∞—Ç 
![out_json](./images/lab05/out_csv.png)
### –ò—Å—Ö–æ–¥–Ω–∏–∫ .csv
![testik_json](./images/lab05/testik_csv.png)
### –†–µ–∑—É–ª—å—Ç–∞—Ç 
![testik_json](./images/lab05/out_json.png)

## –ó–∞–¥–∞–Ω–∏–µ B
``` python
from openpyxl import Workbook
import csv

def csv_to_xlsx(csv_path: str, xlsx_path: str) -> None:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç CSV –≤ XLSX.
    –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å openpyxl –ò–õ–ò xlsxwriter.
    –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ CSV ‚Äî –∑–∞–≥–æ–ª–æ–≤–æ–∫.
    –õ–∏—Å—Ç –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è "Sheet1".
    –ö–æ–ª–æ–Ω–∫–∏ ‚Äî –∞–≤—Ç–æ—à–∏—Ä–∏–Ω–∞ –ø–æ –¥–ª–∏–Ω–µ —Ç–µ–∫—Å—Ç–∞ (–Ω–µ –º–µ–Ω–µ–µ 8 —Å–∏–º–≤–æ–ª–æ–≤).
    """
    new_file = Workbook()
    listt = new_file.active
    listt.title = "1"
    
    with open(csv_path, encoding="utf-8") as f:
        for row in csv.reader(f):
                listt.append(row)
        for column in listt.columns:
            mx = 0
            column_letter = column[0].column_letter
            for cell in column:
                mx = max(mx, len(cell.value))
            new_width = max(mx + 2, 8)
            listt.column_dimensions[column_letter].width = new_width
    
    new_file.save(xlsx_path)
csv_to_xlsx('data/lab05/samples/people.csv', 'data/lab05/out/people.xlsx')  
```
### –ò—Å—Ö–æ–¥–Ω–∏–∫ .csv
![testik_json](./images/lab05/testik_csv.png)
### –†–µ–∑—É–ª—å—Ç–∞—Ç 
![testik_json](./images/lab05/out_xlsx.png)

# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 4
## –ó–∞–¥–∞–Ω–∏–µ 1
```python
from pathlib import Path
import csv
from typing import Iterable, Sequence

def read_text(path: str | Path, encoding: str = "utf-8") -> str:
    """
    –ß–∏—Ç–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–æ–≤ –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É 
    –ß—Ç–æ–±—ã –≤—ã–±—Ä–∞—Ç—å –¥—Ä—É–≥—É—é –∫–æ–¥–∏—Ä–æ–≤–∫—É, –ø—Ä–æ—Å—Ç–æ –º–µ–Ω—è–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –∞—Ä–≥—É–º–µ–Ω—Ç–∞ —Ñ—É–Ω–∫—Ü–∏–∏: 
    read_text("...", "cp1251") - –∑–∞–º–µ–Ω–∏–ª–∏ utf-8 –Ω–∞ cp1251
    """
    p = Path(path)
    return p.read_text(encoding=encoding)
–µ—Å–ª–∏ –Ω—É–∂–Ω–æ —É–±—Ä–∞—Ç—å –ª–∏—á—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã return ''.join(p.read_text(encoding=encoding).split())
print(read_text("data/lab04/input.txt"))
print('*'*18)
def write_csv(rows: list[tuple | list], path: str | Path, header: tuple[str, ...] | None = None) -> None:
    """
    –°–æ–∑–¥–∞–µ–º –∏–ª–∏ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º csv
    + –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã —Å—Ç—Ä–æ–∫ –Ω–∞ –≤—Ö–æ–¥–µ 
    """
    p = Path(path)
    rows = list(rows)
    for i in rows:
        if len(i) != len(header): raise ValueError
    with p.open("w", newline='', encoding="utf-8") as f:
        w = csv.writer(f)
        if header is not None: w.writerow(header)
        for r in rows: w.writerow(r)


write_csv([("word","count","terk"),("test",3, 6)], "data/lab04/check.csv", 'eet') 
write_csv(rows=[], path="data/lab04/check.csv", header=None)
write_csv(rows=[], path="data/lab04/check.csv", header='F')
```

### print(read_text("data/lab04/input.txt"))
![1](./images/lab04/ex01(1).png)

### write_csv([("word","count"),("test",3)], "data/lab04/check.csv", 'ddg') 
![2](./images/lab04/ex01(2).png)

### write_csv(rows=[], path="data/lab04/check.csv", header=None)
![3](./images/lab04/ex01(3).png)

### write_csv(rows=[], path="data/lab04/check.csv", header='F')
![4](./images/lab04/ex01(4).png)

## –ó–∞–¥–∞–Ω–∏–µ 2
```python
import csv
from collections import Counter
from pathlib import Path
import os, sys

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from lib.text import tokenize, normalize, top_n, count_freq

def read_text(path: str | Path, encoding: str = "utf-8") -> str:
    """
    –ß–∏—Ç–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞ 
    + –æ–±—Ä–∞–±–∞—Ç–≤–∞–µ–º –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª
    """
    try:
        p = Path(path)
        return p.read_text(encoding=encoding)
    except FileNotFoundError:
        print('–§–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç')
        sys.exit(1)

nova_str = read_text("data/lab04/input.txt") #—É–º–µ—Å—Ç–Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ txt —Ñ–∞–π–ª
#arg - –ø–æ–¥–∞–≤–∞–µ–º–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ —Ñ—É–Ω–∫—Ü–∏—é 
#if arg[-1:-3] == 'txt' or 'csv':
#–ü—Ä–æ—Ö–æ–¥–∏—Ç —É—Å–ª–æ–≤–∏–µ, –º–æ–∂–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å –¥–∞–ª—å—à–µ 

def frequencies_from_text(text: str) -> dict[str, int]:
    tokens = tokenize(normalize(text))
    return Counter(tokens) 

def sorted_word(freq: dict[str, int]) -> list[tuple[str, int]]:
    return sorted(freq.items(), key=lambda x: (-x[1], x[0]))

def report_csv(word_counts: list[tuple[str, int]], path: str | Path = "report.csv") -> None:
    """
    –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç csv —Ñ–∞–π–ª–æ–º
    word_counts: —Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π 
    path: –ø—É—Ç—å, –ø–æ –∫–æ—Ç–æ—Ä–æ–º—É –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω—è—Ç—å—Å—è –æ—Ç—á–µ—Ç csv 
    """
    p = Path(path)
    with p.open("w", newline='', encoding="utf-8") as f:
        l = csv.writer(f)
        l.writerow(("word", "count"))
        for word, count in word_counts:
            l.writerow((word, count))

sorted_list = sorted_word(frequencies_from_text(nova_str))
report_csv(sorted_list, "data/lab04/report.csv")

print(f'–í—Å–µ–≥–æ —Å–ª–æ–≤: {len((nova_str).split())}')
print(f'–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(set(tokenize(nova_str)))}')
print(f'–¢–æ–ø-5:')
for word, count in top_n(Counter(tokenize(nova_str)), 5):
    print(f'{word}:{count}')

print(f"–û—Ç—á–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: data/lab04/report.csv")
```
### –ö–æ–Ω—Å–æ–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç (mini)
![5](./images/lab04/ex02(1).png)
### Report 
![6](./images/lab04/ex02(2).png)

# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 3
## –ó–∞–¥–∞–Ω–∏–µ 1 (–§—É–Ω–∫—Ü–∏–∏)
```python
def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:
    if text == '': return ''
    if casefold: 
        text = text.casefold()
    if yo2e:
        text = text.replace('—ë','–µ').replace('–Å','–ï')
    text = ' '.join(text.split())
    return text
print(normalize("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t"))
print(normalize("—ë–∂–∏–∫, –Å–ª–∫–∞"))
print(normalize("Hello\r\nWorld"))
print(normalize("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  "))
print('#'*18)
print(' '*18)

def tokenize(text: str) -> list[str]:
    tokenn = []
    perederz = []
    for simv in text+' ':
        if simv.isalnum() or simv == '_':
            perederz.append(simv)
        elif simv == '-' and len(perederz)>=1 and perederz[-1].isalnum():
            perederz.append(simv)        
        else:
            if len(perederz) >=1:   
                tokenn.append(''.join(perederz))
                perederz = []
    return tokenn 
print(tokenize("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"))
print(tokenize("hello,world!!!"))
print(tokenize("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ"))
print(tokenize("2025 –≥–æ–¥"))
print(tokenize("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ"))
print('#'*18)
print(' '*18)

def count_freq(tokens: list[str]) -> dict[str, int]:
    slovar = {}
    for token in tokens:
        slovar[token] = slovar.get(token,0) +1
    return slovar
print(count_freq(["a","b","a","c","b","a"]))
print('#'*18)
print(' '*18) 

def top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]:
    res = list(freq.items())
    res.sort(key = lambda i: (-i[1],i[0]))
    return res
print(top_n({"bb":2,"aa":2,"cc":3}))
print('#'*18)
print(' '*18)
```
![func](./images/lab03/text.png)

## –ó–∞–¥–∞–Ω–∏–µ 2 
```python 
import sys
import os
from pathlib import Path

lib_path = Path(__file__).parent.parent / 'lib'
sys.path.insert(0, str(lib_path))

from text import tokenize, normalize, count_freq, top_n


def read_stdin() -> str:
    return sys.stdin.read()


def stats(colvo_slov: int, unik_slova: int, top_items):
    print(f'–í—Å–µ–≥–æ —Å–ª–æ–≤: {colvo_slov}')
    print(f'–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {unik_slova}')
    print('–¢–æ–ø-5:')
    for word, count in top_items:
        print(f'{word}:{count}')


def main():
    text = read_stdin()
    normalized = normalize(text)
    tokens = tokenize(normalized)
    freq_map = count_freq(tokens)
    top = top_n(freq_map, 5)
    stats(len(tokens), len(set(tokens)), top)


if __name__ == '__main__':
    main()
```
![text_stats](./images/lab03/text_stats.png)


# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 2
## –ó–∞–¥–∞–Ω–∏–µ 1
```python
ddef min_max(nums: list[float | int]) -> tuple[float | int, float | int]:
    if not nums:
        raise ValueError
    return (min(nums), max(nums))
print(min_max([3, -1, 5, 5, 0]))
print(min_max([42]))
print(min_max([-5, -2, -9]))
print(min_max([]))
print(min_max([1.5, 2, 2.0, -3.1]))

print('#'*18)
print('')
def unique_sorted(nums: list[float | int]) -> list[float | int]:
    return sorted(set(nums))
print(unique_sorted([3, 1, 2, 1, 3]))
print(unique_sorted([]))
print(unique_sorted([-1, -1, 0, 2, 2]))
print(unique_sorted([1.0, 1, 2.5, 2.5, 0]))
print('#'*18)
print('')
def flatten(mat: list[list | tuple]) -> list:
    res = []
    for row in mat:
        if not isinstance(row,(list,tuple)):
            raise ValueError
        if isinstance(row,(list,tuple)):
            res.extend(row)
    return res
print(flatten([[1, 2], [3, 4]]))
print(flatten([[1, 2], (3, 4, 5)]))  
print(flatten([[1], [], [2, 3]]))  
print(flatten([[1, 2], "ab"])) 
print('#'*18)
```
![arrays](./images/lab02/ex01.png)

## –ó–∞–¥–∞–Ω–∏–µ 2
```python
def transpose(mat: list[list[float | int]]) -> list[list]:
    if len(mat) == 0:
        return []
    rvan = [len(x) for x in mat]
    if len(set(rvan))!=1:
        raise ValueError
    return [list(col) for col in zip(*mat)]
print(transpose([[1, 2, 3]]))
print(transpose([[1], [2], [3]]))
print(transpose([[1, 2], [3, 4]]))
print(transpose([]))
print(transpose([[1, 2], [3]]))
print('#'*18)
print('')

def row_sums(mat: list[list[float | int]]) -> list[float]:
    rvan = [len(x) for x in mat]
    if len(set(rvan)) != 1:
        raise ValueError
    res = []
    for i in range(len(mat)):
        summ = 0
        res.append(sum(mat[i]))
    return res
print(row_sums([[1, 2, 3], [4, 5, 6]]))
print(row_sums([[-1, 1], [10, -10]]))
print(row_sums([[0, 0], [0, 0]]))
print(row_sums([[1, 2], [3]]))
print('#'*18,' '*18)
print('')

def col_sums(mat: list[list[float | int]]) -> list[float]:
    rvan = [len(x) for x in mat]
    if len(set(rvan)) != 1:
        raise ValueError
    res = []
    for i in range(len(mat[0])):
        s = 0
        for j in range(len(mat)):
            s+=mat[j][i]
        res.append(s)       
    return res
print(col_sums([[1, 2, 3], [4, 5, 6]]))
print(col_sums([[-1, 1], [10, -10]]))
print(col_sums([[0, 0], [0, 0]]))
print(col_sums([[1, 2], [3]]))
print('#'*18)
```
![matrix](./images/lab02/ex02.png)
## –ó–∞–¥–∞–Ω–∏–µ 3
```python
def format_record(rec: tuple[str, str, float]) -> str:
    if not isinstance(rec, tuple):
        raise TypeError #–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–æ—Ä—Ç–µ–∂
    if len(rec) != 3:
        raise ValueError #–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —ç–ª–µ–º–µ–Ω—Ç—ã 
    fio, group,gpa = rec
    if  group == '' or gpa > 5 or gpa < 0 or fio == '':
        raise ValueError #–ù–µ–≤–µ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ(0<gpa<5)
    if not isinstance(gpa,(int,float)) or not isinstance(group,str) or not isinstance(fio,str):
        raise TypeError #–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö  
    stroka = ''
    inic = fio.strip().split()
    if len(inic) == 3:
        inic = str(inic[0][0].upper()+inic[0][1::] + ' ' +(inic[1])[:1:].upper()+'.'+ (inic[2])[:1:].upper()+'.')
    else:
        inic = str(inic[0][0].upper()+inic[0][1::]  +' '+(inic[1])[:1:]+'.')    
    grupa = rec[1]
    ball = f'{gpa:.2f}'
    stroka = inic + ', –≥—Ä. ' + grupa + ', GPA ' + ball 
    return stroka
print(format_record(("–ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á", "BIVT-25", 4.6)))
print(format_record(("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä", "IKBO-12", 5.0)))
print(format_record(("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä –ü–µ—Ç—Ä–æ–≤–∏—á", "IKBO-12", 5.0)))
print(format_record(("  —Å–∏–¥–æ—Ä–æ–≤–∞  –∞–Ω–Ω–∞   —Å–µ—Ä–≥–µ–µ–≤–Ω–∞ ", "ABB-01", 3.999)))
print(format_record(("IKBO-12", 5.0)))
print(format_record(("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä –ü–µ—Ç—Ä–æ–≤–∏—á", 5,4.0)))  
print('#'*18)
```
![tuples](./images/lab02/ex03.png)

# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 1
## –ó–∞–¥–∞–Ω–∏–µ 1
```python
name = input('–ò–º—è: ')
age = int(input('–í–æ–∑—Ä–∞—Å—Ç: '))
print(f'–ü—Ä–∏–≤–µ—Ç, {name}! –ß–µ—Ä–µ–∑ –≥–æ–¥ —Ç–µ–±–µ –±—É–¥–µ—Ç {age+1}.')
```
![name and age](./images/lab01/ex01.png)

## –ó–∞–¥–∞–Ω–∏–µ 2 
```python
a = input('a: ')
b = input('b: ')
a = float(a.replace(',','.'))
b = float(b.replace(',','.'))
print(f'sum={a+b}; avg={((a+b)/2):.2f}')
```
![sum and avg](./images/lab01/ex02.png)

## –ó–∞–¥–∞–Ω–∏–µ 3
```python
price = int(input('price='))
discount = int(input('discount='))
vat = int(input('vat='))
base = price * (1-discount/100)
vat_amount = base * (vat/100)
total = base + vat_amount
print(f'–ë–∞–∑–∞ –ø–æ—Å–ª–µ —Å–∫–∏–¥–∫–∏: {base:.2f} ‚ÇΩ')
print(f'–ù–î–°: {vat_amount:20.2f} ‚ÇΩ')
print(f'–ò—Ç–æ–≥–æ –∫ –æ–ø–ª–∞—Ç–µ: {total:10.2f} ‚ÇΩ')
```
![discount and vat](./images/lab01/ex03.png)

## –ó–∞–¥–∞–Ω–∏–µ 4
```python
m = int(input('–ú–∏–Ω—É—Ç—ã: '))
print(f'{m//60}:{m%60:02d}')
```
![minutes to hhmm](./images/lab01/ex04.png)

## –ó–∞–¥–∞–Ω–∏–µ 5
```python
fio = input('–§–ò–û: ')
fio = fio.replace(' ','')
iniciali = ''
for i in range(len(fio)):
    bukva = fio[i]
    if bukva.isupper():
        iniciali += bukva
    else:
        continue
print(f'–ò–Ω–∏—Ü–∏–∞–ª—ã: {iniciali}.')
print(f'–î–ª–∏–Ω–∞ (—Å–∏–º–≤–æ–ª–æ–≤): {len(fio)+2}')
```
![initials and len](./images/lab01/ex05.png)

## –ó–∞–¥–∞–Ω–∏–µ 6 
```python
kolich = int(input('in_1: '))
ochno_ = 0
zaochno_ = 0
for i in range(kolich):
    ychastnik = input(f'in_{i+2}: ')
    if 'True' in ychastnik:
        ochno_ = ochno_+1
    else:
        zaochno_ = zaochno_ +1
print(f'out: {ochno_} {zaochno_}')
```
![zvezdochka#6](./images/lab01/ex06.png)

## –ó–∞–¥–∞–Ω–∏–µ 7
```python
vxod = input('in: ')
itog_ = ''
index_1 = 0 
index_2 = 0

for i in range(len(vxod)):
    if vxod[i].isupper():
        index_1 = i 
        break
    else:
        continue 
for i in range(len(vxod)):
    if vxod[i] in '0123456789':
        index_2 = i+1
        break
    else:
        continue
shag = index_2 - index_1
for i in range(index_1,len(vxod),shag):
    itog_+=vxod[i]
print(f'out: {itog_}')
```
![zvezdochka#7](./images/lab01/ex07.png)    